{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'opencv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9260edce37a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopencv\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'opencv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import opencv as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = {}\n",
    "objects = ['Car', 'Truck', 'Pedestrian']\n",
    "for line in open('./annotations/0041.txt'):\n",
    "    if line.split(',')[0] in objects:\n",
    "        obj = line.split(',')[0]\n",
    "        frames = line[line.find('{') + 1: line.find('}')]\n",
    "        for f in frames.split(\"',\"):\n",
    "            f = f.strip().replace(\"'\", \"\")\n",
    "            img = f.split(':')[0]\n",
    "            coor = f.split(':')[1]\n",
    "#             print(obj, img, coor)\n",
    "            dec[obj+img] = coor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Car000490': ' [364, 239, 513, 367]',\n",
       " 'Car000495': ' [315, 253, 504, 397]',\n",
       " 'Car000500': ' [320, 254, 540, 416]',\n",
       " 'Car000505': ' [423, 269, 716, 482]',\n",
       " 'Car000510': ' [633, 270, 1091, 692]',\n",
       " 'Car000515': ' [976, 330, 1271, 675]',\n",
       " 'Truck000490': ' [710, 200, 805, 271]',\n",
       " 'Truck000495': ' [686, 204, 777, 267]',\n",
       " 'Truck000500': ' [719, 199, 786, 264]',\n",
       " 'Truck000505': ' [855, 196, 929, 256]',\n",
       " 'Truck000510': ' [970, 185, 1047, 232]',\n",
       " 'Truck000515': ' [1062, 192, 1124, 246]',\n",
       " 'Car000715': ' [684, 327, 781, 400]',\n",
       " 'Car000720': ' [712, 329, 829, 422]',\n",
       " 'Car000725': ' [706, 336, 852, 436]',\n",
       " 'Car000730': ' [692, 339, 900, 460]',\n",
       " 'Car000735': ' [690, 298, 1058, 540]',\n",
       " 'Car000740': ' [805, 278, 1280, 637]',\n",
       " 'Car000865': ' [808, 489, 877, 548]',\n",
       " 'Car000870': ' [820, 496, 913, 572]',\n",
       " 'Car000875': ' [783, 495, 932, 593]',\n",
       " 'Car000880': ' [687, 487, 929, 648]',\n",
       " 'Car000885': ' [507, 468, 979, 699]',\n",
       " 'Car000890': ' [162, 366, 988, 720]',\n",
       " 'Pedestrian000865': ' [887, 489, 914, 535]',\n",
       " 'Pedestrian000870': ' [930, 480, 955, 552]',\n",
       " 'Pedestrian000875': ' [950, 476, 989, 574]',\n",
       " 'Pedestrian000880': ' [953, 467, 1011, 602]',\n",
       " 'Pedestrian000885': ' [990, 443, 1061, 649]',\n",
       " 'Pedestrian000890': ' [1094, 405, 1171, 716]',\n",
       " 'Car001105': ' [377, 229, 487, 267]',\n",
       " 'Car001110': ' [341, 239, 468, 272]',\n",
       " 'Car001115': ' [292, 241, 441, 285]',\n",
       " 'Car001120': ' [253, 243, 414, 292]',\n",
       " 'Car001125': ' [221, 252, 418, 302]',\n",
       " 'Car001130': ' [204, 231, 441, 305]',\n",
       " 'Car001135': ' [224, 227, 465, 311]',\n",
       " 'Car001300': ' [647, 454, 678, 489]',\n",
       " 'Car001305': ' [614, 453, 673, 499]',\n",
       " 'Car001310': ' [573, 441, 680, 497]',\n",
       " 'Car001315': ' [502, 423, 656, 520]',\n",
       " 'Car001320': ' [304, 407, 629, 544]',\n",
       " 'Car001325': ' [5, 360, 656, 689]',\n",
       " 'Car001330': ' [2, 310, 822, 714]',\n",
       " 'Car002210': ' [508, 359, 756, 564]',\n",
       " 'Car002215': ' [521, 364, 750, 560]',\n",
       " 'Car002220': ' [499, 354, 756, 563]',\n",
       " 'Car002225': ' [518, 361, 768, 569]',\n",
       " 'Car002230': ' [501, 363, 757, 566]',\n",
       " 'Car002235': ' [515, 357, 752, 563]',\n",
       " 'Pedestrian002210': ' [439, 324, 464, 470]',\n",
       " 'Pedestrian002215': ' [443, 329, 465, 472]',\n",
       " 'Pedestrian002220': ' [440, 327, 468, 477]',\n",
       " 'Pedestrian002225': ' [443, 326, 468, 479]',\n",
       " 'Pedestrian002230': ' [436, 316, 475, 475]',\n",
       " 'Pedestrian002235': ' [437, 322, 465, 473]',\n",
       " 'Car002940': ' [620, 444, 678, 503]',\n",
       " 'Car002945': ' [626, 460, 670, 501]',\n",
       " 'Car002950': ' [619, 458, 674, 503]',\n",
       " 'Car002955': ' [607, 479, 658, 522]',\n",
       " 'Car002960': ' [623, 536, 675, 579]',\n",
       " 'Car002965': ' [729, 432, 783, 473]',\n",
       " 'Pedestrian002940': ' [741, 464, 761, 500]',\n",
       " 'Pedestrian002945': ' [757, 461, 778, 506]',\n",
       " 'Pedestrian002950': ' [777, 462, 798, 510]',\n",
       " 'Pedestrian002955': ' [791, 463, 814, 524]',\n",
       " 'Pedestrian002960': ' [861, 523, 887, 605]',\n",
       " 'Pedestrian002965': ' [1055, 411, 1083, 518]',\n",
       " 'Car003400': ' [396, 319, 503, 419]',\n",
       " 'Car003405': ' [321, 311, 454, 436]',\n",
       " 'Car003410': ' [327, 297, 524, 474]',\n",
       " 'Car003415': ' [206, 258, 537, 516]',\n",
       " 'Car003420': ' [0, 215, 478, 507]',\n",
       " 'Car003425': ' [0, 156, 339, 549]',\n",
       " 'Car003725': ' [732, 333, 1041, 510]',\n",
       " 'Car003730': ' [739, 311, 1031, 504]',\n",
       " 'Car003735': ' [689, 312, 1019, 518]',\n",
       " 'Car003740': ' [684, 312, 1006, 513]',\n",
       " 'Car003745': ' [661, 319, 1020, 516]',\n",
       " 'Car003750': ' [658, 283, 1180, 545]',\n",
       " 'Car003755': ' [974, 264, 1280, 540]',\n",
       " 'Truck003725': ' [685, 316, 758, 385]',\n",
       " 'Truck003730': ' [687, 322, 768, 377]',\n",
       " 'Truck003735': ' [687, 316, 732, 369]',\n",
       " 'Truck003740': ' [699, 317, 744, 355]',\n",
       " 'Truck003745': ' [703, 311, 749, 347]',\n",
       " 'Truck003750': ' [728, 284, 765, 321]',\n",
       " 'Car004010': ' [569, 375, 658, 406]',\n",
       " 'Car004015': ' [551, 374, 671, 415]',\n",
       " 'Car004020': ' [461, 361, 653, 426]',\n",
       " 'Car004025': ' [407, 336, 631, 437]',\n",
       " 'Car004030': ' [283, 321, 617, 488]',\n",
       " 'Car004035': ' [19, 271, 824, 604]',\n",
       " 'Truck004010': ' [784, 353, 828, 403]',\n",
       " 'Truck004015': ' [792, 356, 850, 410]',\n",
       " 'Truck004020': ' [746, 349, 812, 415]',\n",
       " 'Truck004025': ' [692, 341, 762, 400]',\n",
       " 'Truck004030': ' [578, 334, 660, 396]',\n",
       " 'Truck004035': ' [465, 317, 527, 369]',\n",
       " 'Car004345': ' [0, 497, 286, 652]',\n",
       " 'Car004350': ' [0, 489, 290, 663]',\n",
       " 'Car004355': ' [4, 504, 282, 668]',\n",
       " 'Car004360': ' [0, 493, 308, 670]',\n",
       " 'Car004365': ' [0, 479, 297, 684]',\n",
       " 'Car004370': ' [0, 482, 304, 669]'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = \"'000490': '[364, 239, 513, 367]', '000495': '[315, 253, 504, 397]', '000500': '[320, 254, 540, 416]', '000505': '[423, 269, 716, 482]', '000510': '[633, 270, 1091, 692]', '000515': '[976, 330, 1271, 675]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004345: [0, 497, 286, 652]\n",
      "004350: [0, 489, 290, 663]\n",
      "004355: [4, 504, 282, 668]\n",
      "004360: [0, 493, 308, 670]\n",
      "004365: [0, 479, 297, 684]\n",
      "004370: [0, 482, 304, 669]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/how-to-train-an-object-detection-model-with-keras/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
